import os
import json
import torch
import sys
import numpy as np
import pandas as pd
import argparse
from datetime import datetime

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from prepare_test_data import prepare_test_data
from data_loader import load_or_download_data
from train_model import load_model
from hybrid_model import HybridTransformerConvLSTM

# üìå –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—ã
def validate_date(date_str, default):
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y-%m-%d")
    except ValueError:
        print(f"‚ö† –û—à–∏–±–∫–∞! –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {default}.")
        return default

# üîπ –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
parser.add_argument("--ticker", type=str, default="EURUSD=X", help="–¢–∏–∫–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, AAPL, BTC-USD)")
parser.add_argument("--start_date", type=str, default="2015-01-01", help="–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (YYYY-MM-DD)")
parser.add_argument("--end_date", type=str, default="2025-01-28", help="–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è (YYYY-MM-DD)")
args = parser.parse_args()

# üîÑ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print(f"üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {args.ticker} ({args.start_date} - {args.end_date})")
data, file_path = load_or_download_data(args.ticker, args.start_date, args.end_date)

# 2. üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
seq_length = 30
X_test, scaler = prepare_test_data(data, seq_length=seq_length)

# 3. üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
params_path = os.path.join("saved_models", "best_params.json")
if not os.path.exists(params_path):
    raise FileNotFoundError(f"‚ùå –§–∞–π–ª {params_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")

with open(params_path, "r") as f:
    best_params = json.load(f)

# 4. üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = HybridTransformerConvLSTM(
    input_size=1, d_model=64, nhead=4, num_layers=best_params["num_layers"],
    conv_filters=best_params["conv_filters"], hidden_size=best_params["hidden_size"]
).to(device)

model = load_model(model, "saved_models/hybrid_model.pth")
model.eval()

# ‚úÖ –ü–æ–¥–≥–æ–Ω—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)

# ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Conv1D
X_test_tensor = X_test_tensor.view(X_test_tensor.shape[0], 1, seq_length)  # (batch_size, 1, seq_length)

# üîç –í—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
print(f"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä X_test_tensor –ø–µ—Ä–µ–¥ Conv1D: {X_test_tensor.shape}")

# üîç **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è**
num_days = 30  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–Ω–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
X_test_last_month = X_test[-num_days:]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
dates_last_month = data.index[-num_days:]  # –î–∞—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∞
actual_rsi = data["RSI_21"].values[-num_days:]  # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ RSI

predictions_t1_list, predictions_t2_list, predictions_t3_list = [], [], []

# üîç **–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ**
with torch.no_grad():
    for i in range(num_days):
        X_test_single = X_test_last_month[i].reshape(1, 1, seq_length)  # (batch, channels, seq_length)
        X_test_tensor = torch.tensor(X_test_single, dtype=torch.float32).to(device)

        # ‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
        x = model.conv1(X_test_tensor).permute(0, 2, 1)  # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –¥–ª—è LSTM
        predictions, (hn, cn) = model.lstm(x)  # LSTM —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π

        # ‚úÖ –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è t+1, t+2, t+3
        predictions_t1 = predictions[:, -1, 0].cpu().numpy().flatten()
        predictions_t2 = predictions[:, -1, 1].cpu().numpy().flatten()
        predictions_t3 = predictions[:, -1, 2].cpu().numpy().flatten()

        # üîÑ –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        predictions_t1 = scaler.inverse_transform(predictions_t1.reshape(-1, 1)).flatten()[0]
        predictions_t2 = scaler.inverse_transform(predictions_t2.reshape(-1, 1)).flatten()[0]
        predictions_t3 = scaler.inverse_transform(predictions_t3.reshape(-1, 1)).flatten()[0]

        # ‚úÖ **–î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è**
        predictions_t1_list.append(predictions_t1)
        predictions_t2_list.append(predictions_t2)
        predictions_t3_list.append(predictions_t3)

# üìä **–§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**
df_results = pd.DataFrame({
    "–î–∞—Ç–∞": dates_last_month,
    "–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ RSI": actual_rsi,
    "–ü—Ä–æ–≥–Ω–æ–∑ RSI (t+1)": predictions_t1_list,
    "–ü—Ä–æ–≥–Ω–æ–∑ RSI (t+2)": predictions_t2_list,
    "–ü—Ä–æ–≥–Ω–æ–∑ RSI (t+3)": predictions_t3_list
})

# üìÅ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV**
output_file = "test_results_last_month.csv"
df_results.to_csv(output_file, index=False)
print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")

# üìä **–í—ã–≤–æ–¥ —Ç–∞–±–ª–∏—Ü—ã**
import ace_tools as tools
tools.display_dataframe_to_user(name="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü", dataframe=df_results)

print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
